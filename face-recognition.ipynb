{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "from PIL import Image\n",
    "from shutil import copyfile\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RAW_CLASSES_PATH = \"./full_data_set\"\n",
    "TRAINING_CLASSES_PATH = \"./training_data_set\"\n",
    "VALIDATION_CLASSES_PATH = \"./validation_data_set\"\n",
    "TESTING_CLASSES_PATH = \"./testing_data_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "peopleFolders = os.listdir(RAW_CLASSES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"./haarcascade_frontalface_alt.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cropAllImages(pathClass, sizeImages, scaleImage=1.3):\n",
    "    imagesFileNames = [image for image in os.listdir(pathClass) if image.endswith(\".jpg\")]\n",
    "\n",
    "    for imageFileName in imagesFileNames:\n",
    "        imageFileName = os.path.join(pathClass, imageFileName)\n",
    "        image = cv2.imread(imageFileName)\n",
    "        faces = face_cascade.detectMultiScale(image, scaleFactor=scaleImage)\n",
    "\n",
    "        if len(faces) == 0:\n",
    "            os.remove(imageFileName)\n",
    "        else:\n",
    "            for (x, y, width, height) in faces:\n",
    "                imageResized = cv2.resize(\n",
    "                    image[y: y+height, x: x+width],\n",
    "                    sizeImages,\n",
    "                    interpolation=cv2.INTER_AREA)\n",
    "                cv2.imwrite(imageFileName, imageResized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for personFolder in peopleFolders:\n",
    "    cropAllImages(os.path.join(RAW_CLASSES_PATH, personFolder), (175, 175))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "jsonTrainingImages = json.loads(open(\"training.csv\", \"r\").read())\n",
    "jsonValidationImages = json.loads(open(\"validation.csv\", \"r\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "jsonTrainingImagesLength = 0\n",
    "jsonValidationImagesLength = 0\n",
    "\n",
    "for personFolder in peopleFolders:\n",
    "    pathClass = os.listdir(os.path.join(RAW_CLASSES_PATH, personFolder))\n",
    "\n",
    "    trainingImagesList = jsonTrainingImages.get(personFolder)\n",
    "    validationImagesList = jsonValidationImages.get(personFolder)\n",
    "\n",
    "    jsonTrainingImagesLength += len(trainingImagesList)\n",
    "    jsonValidationImagesLength += len(validationImagesList)\n",
    "\n",
    "    if not os.path.isdir(os.path.join(TRAINING_CLASSES_PATH, personFolder)):\n",
    "        os.mkdir(os.path.join(TRAINING_CLASSES_PATH, personFolder))\n",
    "    if not os.path.isdir(os.path.join(VALIDATION_CLASSES_PATH, personFolder)):\n",
    "        os.mkdir(os.path.join(VALIDATION_CLASSES_PATH, personFolder))\n",
    "\n",
    "    for trainingImage in trainingImagesList:\n",
    "        pathImage = os.path.join(RAW_CLASSES_PATH, personFolder, trainingImage)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(pathImage)\n",
    "            image.verify()\n",
    "\n",
    "            if os.path.getsize(pathImage) > 100 and trainingImage.endswith(\".jpg\") and image.mode == \"RGB\":\n",
    "                copyfile(pathImage, os.path.join(TRAINING_CLASSES_PATH, personFolder, trainingImage))\n",
    "\n",
    "        except:\n",
    "            print(\"Failed to open image: \", personFolder, trainingImage)\n",
    "\n",
    "    for validationImage in validationImagesList:\n",
    "        pathImage = os.path.join(RAW_CLASSES_PATH, personFolder, validationImage)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(pathImage)\n",
    "            image.verify()\n",
    "\n",
    "            if os.path.getsize(pathImage) > 100 and validationImage.endswith(\".jpg\") and image.mode == \"RGB\":\n",
    "                copyfile(pathImage, os.path.join(VALIDATION_CLASSES_PATH, personFolder, validationImage))\n",
    "\n",
    "        except:\n",
    "            print(\"Failed to open image: \", personFolder, validationImage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "editedImageGenerator = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "trainingImagesGenerator = editedImageGenerator.flow_from_directory(TRAINING_CLASSES_PATH,\n",
    "                                                                   target_size=(175, 175),\n",
    "                                                                   batch_size=128,\n",
    "                                                                   class_mode=\"categorical\")\n",
    "\n",
    "editedImageGenerator = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "validationImagesGenerator = editedImageGenerator.flow_from_directory(VALIDATION_CLASSES_PATH,\n",
    "                                                                     target_size=(175, 175),\n",
    "                                                                     batch_size=32,\n",
    "                                                                     class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes = {indexPerson: namePerson for namePerson, indexPerson in trainingImagesGenerator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Conv2D(32,\n",
    "                           (3, 3),\n",
    "                           activation=\"relu\",\n",
    "                           padding=\"same\",\n",
    "                           input_shape=(175, 175, 3)),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32,\n",
    "                           (3, 3),\n",
    "                           activation=\"relu\",\n",
    "                           padding=\"same\"),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64,\n",
    "                           (3, 3),\n",
    "                           activation=\"relu\",\n",
    "                           padding=\"same\"),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64,\n",
    "                           (3, 3),\n",
    "                           activation=\"relu\",\n",
    "                           padding=\"same\"),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64,\n",
    "                           (3, 3),\n",
    "                           activation=\"relu\",\n",
    "                           padding=\"same\"),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(32,\n",
    "                           (3, 3),\n",
    "                           activation=\"relu\",\n",
    "                           padding=\"same\"),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Dense(len(trainingImagesGenerator.class_indices),\n",
    "                          activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "earlyStopping = tf.keras.callbacks.EarlyStopping(patience=12)\n",
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\"faces.h5\",\n",
    "                                                     save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUMBER_EPOCHS = 200\n",
    "\n",
    "historyModel = model.fit(trainingImagesGenerator,\n",
    "                    validationData = validationImagesGenerator,\n",
    "                    epochs=NUMBER_EPOCHS,\n",
    "                    callbacks=[earlyStopping, modelCheckpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(historyModel.history[\"accuracy\"])\n",
    "plt.plot(historyModel.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(historyModel.history[\"loss\"])\n",
    "plt.plot(historyModel.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"faces.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cropAllImages(TESTING_CLASSES_PATH, (175, 175))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imagesFileNamesList = [image for image in os.listdir(\"./\") if image.endswith(\".jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for imageFileName in imagesFileNamesList:\n",
    "    image = tf.keras.preprocessing.image.load_img(imageFileName,\n",
    "                                                  target_size=(175, 175))\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image) / 255.\n",
    "\n",
    "    plt.imshow(image)\n",
    "\n",
    "    index = np.argmax(model.predict(image[tf.newaxis, ...]))\n",
    "\n",
    "    print(classes[index])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}